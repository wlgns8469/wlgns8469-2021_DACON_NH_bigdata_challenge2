{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 외부 데이터 공유 드라이브 :\n",
    "https://drive.google.com/drive/folders/1T3mcWrV4rK8dDyBQk7LnQS6k_YFSCB2r?usp=sharing \n",
    "\n",
    "위의 공유 드라이브에서 데이터 다운로드가 안될 경우 아래의 다운로드 방법 사용 \n",
    "\n",
    "외부 데이터 다운로드 방법 :\n",
    "1. 아래 링크에 들어감\n",
    "https://kr.investing.com/indices/south-korea-indices?&primarySectors=on&otherIndices=on\n",
    "\n",
    "    - 아래 종류 선택    \n",
    "    KOSDAQ Machinery, KRX Transportation, KRX Steel, KRX Media & Telecom, KRX Health Care, KRX Energy & Chemical, KRX Constructions, KRX Semiconductor, KRX Bank, KOSDAQ Entertainment & Culture, KOSDAQ Manufacturing, KOSPI 200 IT\n",
    "\n",
    "    - 윗쪽 부분에 있는 '과거 데이터' 선택\n",
    "    - '데이터 다운로드' 버튼 옆의 날짜 선택 버튼 클릭\n",
    "    - 날짜 지정 시작일자 : 2016/01/01, 종료 일자 : 2020/12/31\n",
    "    - '신청합니다' 버튼 클릭\n",
    "    -  '데이터 다운로드' 버튼 클릭\n",
    "    - 위의 과정을 2번 항목의 데이터들에 대해 반복 수행\n",
    "\n",
    "\n",
    "2. 아래 링크에 들어감\n",
    "http://data.krx.co.kr/contents/MDC/MDI/mdiLoader/index.cmd?menuId=MDC0201\n",
    "    - 왼쪽 메뉴바에서 '지수' -> '주가지수' -> '개별지수 시세추이' 선택\n",
    "    - 지수명에서 종류 검색 : 코스피200, 코스닥150, 코스피200제외 코스피지수\n",
    "    - 아래 조회기간 날짜 지정 : 2016/01/04 ~ 2020/12/30\n",
    "    - '조회' 클릭\n",
    "    - '조화' 버튼 아래 파란색 '다운로드' 클릭 후 csv 파일 다운로드<br><br>\n",
    "    - <span style=\"color:red\">직접 다운로드 시,  csv 파일의 경우 다운받은 날짜에 따라 이름이 바뀌어 파일 경로의 파일명도 변경해줘야 함</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_row\", 100)\n",
    "pd.set_option(\"display.max_column\", 100)\n",
    "import numpy as np\n",
    "import os\n",
    "import sklearn\n",
    "import re\n",
    "import matplotlib\n",
    "import tqdm as tq\n",
    "import copy\n",
    "import lightgbm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.model_selection import KFold\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\programdata\\anaconda3\\lib\\site-packages (1.2.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2021.1)\n",
      "Requirement already satisfied: numpy>=1.16.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (1.20.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
      "Requirement already satisfied: matplotlib in c:\\programdata\\anaconda3\\lib\\site-packages (3.3.4)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: numpy>=1.15 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (1.20.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (8.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: six in c:\\programdata\\anaconda3\\lib\\site-packages (from cycler>=0.10->matplotlib) (1.15.0)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (4.59.0)\n",
      "Requirement already satisfied: sklearn in c:\\programdata\\anaconda3\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\programdata\\anaconda3\\lib\\site-packages (from sklearn) (0.24.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.0.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.20.1)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.6.2)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (1.20.1)\n"
     ]
    }
   ],
   "source": [
    "! pip install pandas\n",
    "! pip install matplotlib\n",
    "! pip install tqdm\n",
    "! pip install sklearn\n",
    "! pip install numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 개발 OS 환경"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 개발 환경(OS): Windows 10 Pro, 64비트 운영 체제, x64 기반 프로세서"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library version 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------- Python & library version --------------------------\n",
    "- Python version: 3.8.5 (default, Sep  3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]\n",
    "- pandas version: 1.2.0\n",
    "- numpy version: 1.19.2\n",
    "- sklearn version: 0.23.2\n",
    "- matplotlib version: 3.3.2\n",
    "- tqdm version: 4.62.2\n",
    "- lightgbm version: 3.1.1\n",
    "------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------- Python & library version --------------------------\n",
      "Python version: 3.8.8 (default, Apr 13 2021, 15:08:03) [MSC v.1916 64 bit (AMD64)]\n",
      "pandas version: 1.2.4\n",
      "numpy version: 1.20.1\n",
      "sklearn version: 0.24.1\n",
      "matplotlib version: 3.3.4\n",
      "tqdm version: 4.59.0\n",
      "lightgbm version: 3.2.1\n",
      "------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"-------------------------- Python & library version --------------------------\")\n",
    "print(\"Python version: {}\".format(sys.version))\n",
    "print(\"pandas version: {}\".format(pd.__version__))\n",
    "print(\"numpy version: {}\".format(np.__version__))\n",
    "print(\"sklearn version: {}\".format(sklearn.__version__))\n",
    "print(\"matplotlib version: {}\".format(matplotlib.__version__))\n",
    "print(\"tqdm version: {}\".format(tq.__version__))\n",
    "print(\"lightgbm version: {}\".format(lightgbm.__version__))\n",
    "print(\"------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 주어진 데이터 및 외부 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cus = pd.read_csv(\"data/cus_info.csv\")\n",
    "iem = pd.read_csv(\"data/iem_info_20210902.csv\")\n",
    "hist = pd.read_csv(\"data/stk_bnc_hist.csv\")\n",
    "train = pd.read_csv(\"data/stk_hld_train.csv\")\n",
    "test = pd.read_csv(\"data/stk_hld_test.csv\")\n",
    "submission = pd.read_csv(\"data/sample_submission.csv\")\n",
    "\n",
    "# 코스피 200 지수\n",
    "kospi = pd.read_csv('data/data_5320_20211011.csv', encoding='cp949')\n",
    "# 코스닥 150 지수\n",
    "kosdaq = pd.read_csv('data/data_5419_20211011.csv', encoding='cp949')\n",
    "# 코스피 200제외 코스피 지수\n",
    "other = pd.read_csv('data/data_5517_20211011.csv', encoding='cp949')\n",
    "\n",
    "# 건설 : 01\n",
    "construction_krx =  pd.read_csv(\"data/KRX Constructions 내역.csv\", thousands = ',')\n",
    "# 금융 : 02\n",
    "bank_krx =  pd.read_csv(\"data/KRX Bank 내역.csv\", thousands = ',')\n",
    "# 기계 : 03\n",
    "machine_krx = pd.read_csv(\"data/KOSDAQ Machinery 내역.csv\", thousands = ',' )\n",
    "#통신 : 04 \n",
    "telecom_krx =  pd.read_csv(\"data/KRX Media & Telecom 내역.csv\", thousands = ',')\n",
    "# 서비스 : 05\n",
    "entertainment_kosdaq =   pd.read_csv(\"data/KOSDAQ Entertainment & Culture 내역.csv\", thousands = ',')\n",
    "# 운송 : 06\n",
    "transportation_krx= pd.read_csv(\"data/KRX Transportation 내역.csv\", thousands = ',')\n",
    "# 유통 : 07\n",
    "transportation_krx= pd.read_csv(\"data/KRX Transportation 내역.csv\", thousands = ',')\n",
    "# 의료 : 08\n",
    "medical_krx =  pd.read_csv(\"data/KRX Health Care 내역.csv\", thousands = ',')\n",
    "# 전기 : 09\n",
    "electric_krx =  pd.read_csv(\"data/KRX Semiconductor 내역.csv\", thousands = ',')\n",
    "# 제조 : 10\n",
    "manufacturing_kosdaq =   pd.read_csv(\"data/KOSDAQ Manufacturing 내역.csv\", thousands = ',')\n",
    "# 철강 : 11\n",
    "steel_krx= pd.read_csv(\"data/KRX Steel 내역.csv\", thousands = ',')\n",
    "# 화학 : 12\n",
    "chemical_krx =  pd.read_csv(\"data/KRX Energy & Chemical 내역.csv\", thousands = ',')\n",
    "# IT : 13\n",
    "IT_kospi =   pd.read_csv(\"data/KOSPI 200 IT 내역.csv\", thousands = ',')\n",
    "\n",
    "# 기타 : 14\n",
    "# 종가만 사용하기 때문에 임이의 KRX 건설(01) csv파일을 가져온 후 모든 업종 지수의 종가 평균을 구함\n",
    "etc_krx = pd.read_csv(\"data/KRX Constructions 내역.csv\", thousands = ',')\n",
    "etc_krx['종가'] = etc_krx['종가'] + bank_krx['종가'] + machine_krx['종가'] + telecom_krx['종가'] + entertainment_kosdaq['종가'] + transportation_krx['종가'] + transportation_krx['종가'] +medical_krx['종가'] + electric_krx['종가'] + manufacturing_kosdaq['종가'] + steel_krx['종가'] + chemical_krx['종가'] + IT_kospi['종가']\n",
    "etc_krx['종가'] = etc_krx['종가'] /13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 외부 데이터의 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleansing(df):\n",
    "    df[\"거래량\"] = df[\"거래량\"].str.replace(pat=r'[^\\w]', repl=r'', regex=True)\n",
    "    df['날짜']=df['날짜'].str.replace(pat=r'[ㄱ-ㅣ가-힣]+', repl= r'', regex=True)\n",
    "    df['날짜'] =df['날짜'].str.replace(\" \",\"\").astype(int)\n",
    "    df['변동 %'] =df['변동 %'].str.replace(\"%\",\"\")\n",
    "    df['거래량'] =df['거래량'].str.replace(\"B\",\"0000000\")\n",
    "    df['거래량'] =df['거래량'].str.replace(\"M\",\"0000\")\n",
    "    df['거래량'] =df['거래량'].str.replace(\"K\",\"0\")\n",
    "    df['거래량'] = df['거래량'].astype(int)\n",
    "    \n",
    "def kos_data_cleansing(df):\n",
    "    df['일자'] =df['일자'].str.replace(\"/\",\"\").astype(str)\n",
    "    df['일자'] = df['일자'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_cleansing(machine_krx)\n",
    "data_cleansing(transportation_krx)\n",
    "data_cleansing(steel_krx)\n",
    "data_cleansing(telecom_krx)\n",
    "data_cleansing(medical_krx)\n",
    "data_cleansing(chemical_krx)\n",
    "data_cleansing(construction_krx)\n",
    "data_cleansing(electric_krx)\n",
    "data_cleansing(bank_krx)\n",
    "data_cleansing(entertainment_kosdaq)\n",
    "data_cleansing(manufacturing_kosdaq)\n",
    "data_cleansing(IT_kospi)\n",
    "data_cleansing(etc_krx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"hist_d\"] = train[\"hold_d\"]*0.6\n",
    "train.hist_d = np.trunc(train[\"hist_d\"])\n",
    "\n",
    "train_data = pd.merge(train, cus, how = \"left\", on = [\"act_id\"])\n",
    "train_data = pd.merge(train_data, iem, how = \"left\", on = [\"iem_cd\"])\n",
    "\n",
    "test_data = pd.merge(test, cus, how = \"left\", on = [\"act_id\"])\n",
    "test_data = pd.merge(test_data, iem, how = \"left\", on = [\"iem_cd\"])\n",
    "\n",
    "train_data['kos_idx'] = 0\n",
    "test_data['kos_idx'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 코스피200, 코스닥150, 기타(코스피200제외 코스피)의 사용하지 않는 컬럼 제외\n",
    "- 3개의 데이터 프레임에서 같은 이름을 가진 컬럼의 이름을 구분하기 위해 이름 변경\n",
    "- 3개의 데이터 프레임을 일자를 기준으로 하나의 데이터 프레임으로 합\n",
    "- 데이터 전처리에서 자주 사용하는 컬럼 데이터 리스트에 저장 후 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "kos_data_cleansing(kospi)\n",
    "kos_data_cleansing(kosdaq)\n",
    "kos_data_cleansing(other)\n",
    "\n",
    "kospi = kospi.drop(['대비', '시가','고가','저가','거래량','거래대금','상장시가총액'], axis = 1)\n",
    "kosdaq = kosdaq.drop(['대비', '시가','고가','저가','거래량','거래대금','상장시가총액'], axis = 1)\n",
    "other = other.drop(['대비', '시가','고가','저가','거래량','거래대금','상장시가총액'], axis = 1)\n",
    "\n",
    "\n",
    "kospi.rename(columns={'종가':'kospi'}, inplace=True)\n",
    "kospi.rename(columns={'등락률':'kospi_idx'}, inplace=True)\n",
    "\n",
    "kosdaq.rename(columns={'종가':'kosdaq'}, inplace=True)\n",
    "kosdaq.rename(columns={'등락률':'kosdaq_idx'}, inplace=True)\n",
    "\n",
    "other.rename(columns={'종가':'other'}, inplace=True)\n",
    "other.rename(columns={'등락률':'other_idx'}, inplace=True)\n",
    "\n",
    "train_data['kos_idx'] = 0\n",
    "test_data['kos_idx'] = 0\n",
    "\n",
    "byn_dt_train = list(train_data['byn_dt'])\n",
    "hold_d_train = list(train_data['hold_d'])\n",
    "stk_dit_cd_train = list(train_data['stk_dit_cd'])\n",
    "byn_dt_test = list(test_data['byn_dt'])\n",
    "hist_d_test = list(test_data['hist_d'])\n",
    "stk_dit_cd_test = list(test_data['stk_dit_cd'])\n",
    "\n",
    "kos_idx_train = []\n",
    "kos_idx_test = []\n",
    "\n",
    "kos_data = pd.merge(kospi, kosdaq, how= \"left\", on = [\"일자\"])\n",
    "kos_data = pd.merge(kos_data, other, how= \"left\", on = [\"일자\"])\n",
    "kos_data.rename(columns={'일자':'byn_dt'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 시장구분(stk_dit_cd) 기준 feature\n",
    "\n",
    "- 새로운 feature을 만들기 위해 stk_dit_cd의 정보를 이용함\n",
    "- 고객이 거래한 종목이 속한 시장과  매수일과 매도일을 바탕으로 해당 종목이 속한 시장의 지수 등락값을 구할 수 있음\n",
    "- train_data와 test_data별로 인덱스에 맞게 새로 만들어준 kos_idx_train, kos_idx_test에 값을 저장하여 사용\n",
    "\n",
    "- train_data에서 모든 데이터에 대한 지수 등락값의 분포를 그래프로 확인해본 결과 중앙값을 기준으로 정규분포로 분포함을 확인하였음\n",
    "- 하지만 test_data 에서는 정규분포를 따르지 않았는데 이는 매도일을 정하는 과정에서 실제 보유일(hold_d)를 사용하는 것이 아닌 hist_d를 이용하여 그런것이라 생각함\n",
    "- 따라서 test_data도 hold_d를 이용하여 얻은 지수 등락값의 분포를 확인하면 정규분포일 것이라는 가정\n",
    "- test_data에서 각 데이터의 지수 등락값과 모든 데이터의 지수 등락값의 중앙값의 차이를 하루평균 지수 상승량으로 나누어 주어 21년 보유일 (hold_d - hist_d)을 구하였음\n",
    "- 이 과정에서 21년 보유일은 0~146일 이기 때문에 146 초과 및 0 미만의 경우 각각 146과 0으로 값을 보정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rate: 100%|████████████████████████████████████████████████████████████████████| 70596/70596 [00:24<00:00, 2840.68it/s]\n",
      "rate: 100%|██████████████████████████████████████████████████████████████████| 681472/681472 [05:09<00:00, 2200.04it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(byn_dt_test)), desc = 'rate', mininterval = 0.01):\n",
    "    if stk_dit_cd_test[i] == 1:\n",
    "        kos_idx_test.append((kos_data['kospi'][list(kos_data['byn_dt']).index(byn_dt_test[i])-hist_d_test[i]+1]-kos_data['kospi'][list(kos_data['byn_dt']).index(byn_dt_test[i])]))\n",
    "        \n",
    "    elif stk_dit_cd_test[i] ==2:\n",
    "      \n",
    "        kos_idx_test.append((kos_data['kosdaq'][list(kos_data['byn_dt']).index(byn_dt_test[i])-hist_d_test[i]+1]-kos_data['kosdaq'][list(kos_data['byn_dt']).index(byn_dt_test[i])]))\n",
    "    else:\n",
    "        kos_idx_test.append((kos_data['other'][list(kos_data['byn_dt']).index(byn_dt_test[i])-hist_d_test[i]+1]-kos_data['other'][list(kos_data['byn_dt']).index(byn_dt_test[i])]))\n",
    "\n",
    "for i in tqdm(range(len(byn_dt_train)), desc = 'rate', mininterval = 0.01):\n",
    "    if stk_dit_cd_train[i] == 1:\n",
    "        kos_idx_train.append((kos_data['kospi'][list(kos_data['byn_dt']).index(byn_dt_train[i])-hold_d_train[i]+1]-kos_data['kospi'][list(kos_data['byn_dt']).index(byn_dt_train[i])]))\n",
    "        \n",
    "    elif stk_dit_cd_train[i] ==2:\n",
    "      \n",
    "        kos_idx_train.append((kos_data['kosdaq'][list(kos_data['byn_dt']).index(byn_dt_train[i])-hold_d_train[i]+1]-kos_data['kosdaq'][list(kos_data['byn_dt']).index(byn_dt_train[i])]))\n",
    "    else:\n",
    "        kos_idx_train.append((kos_data['other'][list(kos_data['byn_dt']).index(byn_dt_train[i])-hold_d_train[i]+1]-kos_data['other'][list(kos_data['byn_dt']).index(byn_dt_train[i])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rate: 100%|███████████████████████████████████████████████████████████████████| 70596/70596 [00:00<00:00, 98011.05it/s]\n",
      "rate: 100%|█████████████████████████████████████████████████████████████████| 681472/681472 [00:08<00:00, 82674.33it/s]\n"
     ]
    }
   ],
   "source": [
    "train_data['kos_idx'] = kos_idx_train\n",
    "test_data['kos_idx'] = kos_idx_test\n",
    "\n",
    "kos_per_day = (kos_data['kospi'][0] - kos_data['kospi'][1226])/len(kos_data)\n",
    "\n",
    "test_kos_idx = copy.deepcopy(test_data['kos_idx'])\n",
    "train_kos_idx = copy.deepcopy(train_data['kos_idx'])\n",
    "\n",
    "test_kos_idx = (test_data['kos_idx'].max() + test_data['kos_idx'].min())/2 - test_kos_idx \n",
    "train_kos_idx = (train_data['kos_idx'].max() + train_data['kos_idx'].min())/2 - train_kos_idx \n",
    "\n",
    "test_kos_idx = test_kos_idx / kos_per_day\n",
    "train_kos_idx = train_kos_idx / kos_per_day\n",
    "\n",
    "for i in tqdm(range(len(test_kos_idx)), desc = 'rate', mininterval = 0.01):\n",
    "    if test_kos_idx[i] < 0:\n",
    "        test_kos_idx[i] = 0\n",
    "        \n",
    "for i in tqdm(range(len(train_kos_idx)), desc = 'rate', mininterval = 0.01):\n",
    "    if train_kos_idx[i] < 0:\n",
    "        train_kos_idx[i] = 0\n",
    "        \n",
    "test_kos_idx = test_kos_idx * (146/test_kos_idx.max())\n",
    "train_kos_idx = train_kos_idx * (146/train_kos_idx.max())\n",
    "\n",
    "test_kos_idx = np.trunc(test_kos_idx)\n",
    "train_kos_idx = np.trunc(train_kos_idx)\n",
    "\n",
    "train_data['kos_idx'] = train_kos_idx\n",
    "test_data['kos_idx'] = test_kos_idx\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>act_id</th>\n",
       "      <th>iem_cd</th>\n",
       "      <th>byn_dt</th>\n",
       "      <th>hold_d</th>\n",
       "      <th>hist_d</th>\n",
       "      <th>sex_dit_cd</th>\n",
       "      <th>cus_age_stn_cd</th>\n",
       "      <th>ivs_icn_cd</th>\n",
       "      <th>cus_aet_stn_cd</th>\n",
       "      <th>mrz_pdt_tp_sgm_cd</th>\n",
       "      <th>lsg_sgm_cd</th>\n",
       "      <th>tco_cus_grd_cd</th>\n",
       "      <th>tot_ivs_te_sgm_cd</th>\n",
       "      <th>mrz_btp_dit_cd</th>\n",
       "      <th>iem_krl_nm</th>\n",
       "      <th>btp_cfc_cd</th>\n",
       "      <th>mkt_pr_tal_scl_tp_cd</th>\n",
       "      <th>stk_dit_cd</th>\n",
       "      <th>kos_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0ad104dbed99be0cd858aa772765ddedade554601a981b...</td>\n",
       "      <td>A006360</td>\n",
       "      <td>20180726</td>\n",
       "      <td>11</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>GS건설</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0ad104dbed99be0cd858aa772765ddedade554601a981b...</td>\n",
       "      <td>A005930</td>\n",
       "      <td>20180131</td>\n",
       "      <td>80</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>삼성전자</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0ad104dbed99be0cd858aa772765ddedade554601a981b...</td>\n",
       "      <td>A005070</td>\n",
       "      <td>20180517</td>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>코스모신소재</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>99</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0ad104dbed99be0cd858aa772765ddedade554601a981b...</td>\n",
       "      <td>A003520</td>\n",
       "      <td>20201112</td>\n",
       "      <td>22</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>영진약품</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0ad104dbed99be0cd858aa772765ddedade554601a981b...</td>\n",
       "      <td>A002310</td>\n",
       "      <td>20180905</td>\n",
       "      <td>324</td>\n",
       "      <td>194.0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>아세아제지</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>99</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681467</th>\n",
       "      <td>4561928f2825f6389f228088ac807a9fb4575ffdcbc47a...</td>\n",
       "      <td>A260660</td>\n",
       "      <td>20180831</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>알리코제약</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>99</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681468</th>\n",
       "      <td>4561928f2825f6389f228088ac807a9fb4575ffdcbc47a...</td>\n",
       "      <td>A271980</td>\n",
       "      <td>20201027</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>제일약품</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>99</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681469</th>\n",
       "      <td>4561928f2825f6389f228088ac807a9fb4575ffdcbc47a...</td>\n",
       "      <td>A289080</td>\n",
       "      <td>20181121</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>SV인베스트먼트</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>99</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681470</th>\n",
       "      <td>4561928f2825f6389f228088ac807a9fb4575ffdcbc47a...</td>\n",
       "      <td>A307930</td>\n",
       "      <td>20200214</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>컴퍼니케이</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>99</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681471</th>\n",
       "      <td>4561928f2825f6389f228088ac807a9fb4575ffdcbc47a...</td>\n",
       "      <td>A308100</td>\n",
       "      <td>20200116</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>까스텔바작</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>99</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>681472 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   act_id   iem_cd    byn_dt  \\\n",
       "0       0ad104dbed99be0cd858aa772765ddedade554601a981b...  A006360  20180726   \n",
       "1       0ad104dbed99be0cd858aa772765ddedade554601a981b...  A005930  20180131   \n",
       "2       0ad104dbed99be0cd858aa772765ddedade554601a981b...  A005070  20180517   \n",
       "3       0ad104dbed99be0cd858aa772765ddedade554601a981b...  A003520  20201112   \n",
       "4       0ad104dbed99be0cd858aa772765ddedade554601a981b...  A002310  20180905   \n",
       "...                                                   ...      ...       ...   \n",
       "681467  4561928f2825f6389f228088ac807a9fb4575ffdcbc47a...  A260660  20180831   \n",
       "681468  4561928f2825f6389f228088ac807a9fb4575ffdcbc47a...  A271980  20201027   \n",
       "681469  4561928f2825f6389f228088ac807a9fb4575ffdcbc47a...  A289080  20181121   \n",
       "681470  4561928f2825f6389f228088ac807a9fb4575ffdcbc47a...  A307930  20200214   \n",
       "681471  4561928f2825f6389f228088ac807a9fb4575ffdcbc47a...  A308100  20200116   \n",
       "\n",
       "        hold_d  hist_d  sex_dit_cd  cus_age_stn_cd  ivs_icn_cd  \\\n",
       "0           11     6.0           1               9           3   \n",
       "1           80    48.0           1               9           3   \n",
       "2            5     3.0           1               9           3   \n",
       "3           22    13.0           1               9           3   \n",
       "4          324   194.0           1               9           3   \n",
       "...        ...     ...         ...             ...         ...   \n",
       "681467       1     0.0           1               4           4   \n",
       "681468       1     0.0           1               4           4   \n",
       "681469       1     0.0           1               4           4   \n",
       "681470       1     0.0           1               4           4   \n",
       "681471       1     0.0           1               4           4   \n",
       "\n",
       "        cus_aet_stn_cd  mrz_pdt_tp_sgm_cd  lsg_sgm_cd  tco_cus_grd_cd  \\\n",
       "0                    2                  2           9               5   \n",
       "1                    2                  2           9               5   \n",
       "2                    2                  2           9               5   \n",
       "3                    2                  2           9               5   \n",
       "4                    2                  2           9               5   \n",
       "...                ...                ...         ...             ...   \n",
       "681467               2                  2           3               4   \n",
       "681468               2                  2           3               4   \n",
       "681469               2                  2           3               4   \n",
       "681470               2                  2           3               4   \n",
       "681471               2                  2           3               4   \n",
       "\n",
       "        tot_ivs_te_sgm_cd  mrz_btp_dit_cd iem_krl_nm  btp_cfc_cd  \\\n",
       "0                       5               8       GS건설           1   \n",
       "1                       5               8       삼성전자           9   \n",
       "2                       5               8     코스모신소재          12   \n",
       "3                       5               8       영진약품           8   \n",
       "4                       5               8      아세아제지          10   \n",
       "...                   ...             ...        ...         ...   \n",
       "681467                  3               8      알리코제약          10   \n",
       "681468                  3               8       제일약품           8   \n",
       "681469                  3               8   SV인베스트먼트           2   \n",
       "681470                  3               8      컴퍼니케이           2   \n",
       "681471                  3               8      까스텔바작           7   \n",
       "\n",
       "        mkt_pr_tal_scl_tp_cd  stk_dit_cd  kos_idx  \n",
       "0                          1           1      4.0  \n",
       "1                          1           1      6.0  \n",
       "2                          2          99      3.0  \n",
       "3                          2           1      0.0  \n",
       "4                          3          99     42.0  \n",
       "...                      ...         ...      ...  \n",
       "681467                     3          99      4.0  \n",
       "681468                     2          99      4.0  \n",
       "681469                     2          99      4.0  \n",
       "681470                     3          99      4.0  \n",
       "681471                     3          99      4.0  \n",
       "\n",
       "[681472 rows x 19 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 종목 업종(btp_cfc_cd) 기준 feature\n",
    "- 위에서는 종목이 속한 시장으로 기준을 나눴다면 아래에서는 종목의 업종을 기준으로 나눔\n",
    "- 과정은 위와 동일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rate: 100%|██████████████████████████████████████████████████████████████████| 681472/681472 [05:19<00:00, 2132.46it/s]\n",
      "rate: 100%|████████████████████████████████████████████████████████████████████| 70596/70596 [00:32<00:00, 2190.38it/s]\n"
     ]
    }
   ],
   "source": [
    "krx_idx_train = []\n",
    "krx_idx_test = []\n",
    "\n",
    "btp_cfc_cd_train = list(train_data['btp_cfc_cd'])\n",
    "btp_cfc_cd_test = list(test_data['btp_cfc_cd'])\n",
    "\n",
    "for i in tqdm(range(len(btp_cfc_cd_train)), desc = 'rate', mininterval = 0.01):\n",
    "    if btp_cfc_cd_train[i] == 1:\n",
    "        krx_idx_train.append((construction_krx['종가'][list(construction_krx['날짜']).index(byn_dt_train[i])-hold_d_train[i]+1]-construction_krx['종가'][list(construction_krx['날짜']).index(byn_dt_train[i])]))\n",
    "    elif btp_cfc_cd_train[i] == 2:\n",
    "        krx_idx_train.append((bank_krx['종가'][list(bank_krx['날짜']).index(byn_dt_train[i])-hold_d_train[i]+1]-bank_krx['종가'][list(bank_krx['날짜']).index(byn_dt_train[i])]))\n",
    "    elif btp_cfc_cd_train[i] == 3:\n",
    "        krx_idx_train.append((machine_krx['종가'][list(machine_krx['날짜']).index(byn_dt_train[i])-hold_d_train[i]+1]-machine_krx['종가'][list(machine_krx['날짜']).index(byn_dt_train[i])]))\n",
    "    elif btp_cfc_cd_train[i] == 4:\n",
    "        krx_idx_train.append((telecom_krx['종가'][list(telecom_krx['날짜']).index(byn_dt_train[i])-hold_d_train[i]+1]-telecom_krx['종가'][list(telecom_krx['날짜']).index(byn_dt_train[i])]))\n",
    "    elif btp_cfc_cd_train[i] == 5:\n",
    "        krx_idx_train.append((entertainment_kosdaq['종가'][list(entertainment_kosdaq['날짜']).index(byn_dt_train[i])-hold_d_train[i]+1]-entertainment_kosdaq['종가'][list(entertainment_kosdaq['날짜']).index(byn_dt_train[i])]))\n",
    "    elif btp_cfc_cd_train[i] == 6:\n",
    "        krx_idx_train.append((transportation_krx['종가'][list(transportation_krx['날짜']).index(byn_dt_train[i])-hold_d_train[i]+1]-transportation_krx['종가'][list(transportation_krx['날짜']).index(byn_dt_train[i])]))\n",
    "    elif btp_cfc_cd_train[i] == 7:\n",
    "        krx_idx_train.append((transportation_krx['종가'][list(transportation_krx['날짜']).index(byn_dt_train[i])-hold_d_train[i]+1]-transportation_krx['종가'][list(transportation_krx['날짜']).index(byn_dt_train[i])]))\n",
    "    elif btp_cfc_cd_train[i] == 8:\n",
    "        krx_idx_train.append((medical_krx['종가'][list(medical_krx['날짜']).index(byn_dt_train[i])-hold_d_train[i]+1]-medical_krx['종가'][list(medical_krx['날짜']).index(byn_dt_train[i])]))\n",
    "    elif btp_cfc_cd_train[i] == 9:\n",
    "        krx_idx_train.append((electric_krx['종가'][list(electric_krx['날짜']).index(byn_dt_train[i])-hold_d_train[i]+1]-electric_krx['종가'][list(electric_krx['날짜']).index(byn_dt_train[i])]))\n",
    "    elif btp_cfc_cd_train[i] == 10:\n",
    "        krx_idx_train.append((manufacturing_kosdaq['종가'][list(manufacturing_kosdaq['날짜']).index(byn_dt_train[i])-hold_d_train[i]+1]-manufacturing_kosdaq['종가'][list(manufacturing_kosdaq['날짜']).index(byn_dt_train[i])]))\n",
    "    elif btp_cfc_cd_train[i] == 11:\n",
    "        krx_idx_train.append((steel_krx['종가'][list(steel_krx['날짜']).index(byn_dt_train[i])-hold_d_train[i]+1]-steel_krx['종가'][list(steel_krx['날짜']).index(byn_dt_train[i])]))\n",
    "    elif btp_cfc_cd_train[i] == 12:\n",
    "        krx_idx_train.append((chemical_krx['종가'][list(chemical_krx['날짜']).index(byn_dt_train[i])-hold_d_train[i]+1]-chemical_krx['종가'][list(chemical_krx['날짜']).index(byn_dt_train[i])]))\n",
    "    elif btp_cfc_cd_train[i] == 13:\n",
    "        krx_idx_train.append((IT_kospi['종가'][list(IT_kospi['날짜']).index(byn_dt_train[i])-hold_d_train[i]+1]-IT_kospi['종가'][list(IT_kospi['날짜']).index(byn_dt_train[i])]))        \n",
    "    else:\n",
    "        krx_idx_train.append((etc_krx['종가'][list(etc_krx['날짜']).index(byn_dt_train[i])-hold_d_train[i]+1]-etc_krx['종가'][list(etc_krx['날짜']).index(byn_dt_train[i])]))\n",
    "        \n",
    "for i in tqdm(range(len(btp_cfc_cd_test)), desc = 'rate', mininterval = 0.01):\n",
    "    if btp_cfc_cd_test[i] == 1:\n",
    "        krx_idx_test.append((construction_krx['종가'][list(construction_krx['날짜']).index(byn_dt_test[i])-hist_d_test[i]+1]-construction_krx['종가'][list(construction_krx['날짜']).index(byn_dt_test[i])]))\n",
    "    elif btp_cfc_cd_test[i] == 2:\n",
    "        krx_idx_test.append((bank_krx['종가'][list(bank_krx['날짜']).index(byn_dt_test[i])-hist_d_test[i]+1]-bank_krx['종가'][list(bank_krx['날짜']).index(byn_dt_test[i])]))\n",
    "    elif btp_cfc_cd_test[i] == 3:\n",
    "        krx_idx_test.append((machine_krx['종가'][list(machine_krx['날짜']).index(byn_dt_test[i])-hist_d_test[i]+1]-machine_krx['종가'][list(machine_krx['날짜']).index(byn_dt_test[i])]))\n",
    "    elif btp_cfc_cd_test[i] == 4:\n",
    "        krx_idx_test.append((telecom_krx['종가'][list(telecom_krx['날짜']).index(byn_dt_test[i])-hist_d_test[i]+1]-telecom_krx['종가'][list(telecom_krx['날짜']).index(byn_dt_test[i])]))\n",
    "    elif btp_cfc_cd_test[i] == 5:\n",
    "        krx_idx_test.append((entertainment_kosdaq['종가'][list(entertainment_kosdaq['날짜']).index(byn_dt_test[i])-hist_d_test[i]+1]-entertainment_kosdaq['종가'][list(entertainment_kosdaq['날짜']).index(byn_dt_test[i])]))\n",
    "    elif btp_cfc_cd_test[i] == 6:\n",
    "        krx_idx_test.append((transportation_krx['종가'][list(transportation_krx['날짜']).index(byn_dt_test[i])-hist_d_test[i]+1]-transportation_krx['종가'][list(transportation_krx['날짜']).index(byn_dt_test[i])]))\n",
    "    elif btp_cfc_cd_test[i] == 7:\n",
    "        krx_idx_test.append((transportation_krx['종가'][list(transportation_krx['날짜']).index(byn_dt_test[i])-hist_d_test[i]+1]-transportation_krx['종가'][list(transportation_krx['날짜']).index(byn_dt_test[i])]))\n",
    "    elif btp_cfc_cd_test[i] == 8:\n",
    "        krx_idx_test.append((medical_krx['종가'][list(medical_krx['날짜']).index(byn_dt_test[i])-hist_d_test[i]+1]-medical_krx['종가'][list(medical_krx['날짜']).index(byn_dt_test[i])]))\n",
    "    elif btp_cfc_cd_test[i] == 9:\n",
    "        krx_idx_test.append((electric_krx['종가'][list(electric_krx['날짜']).index(byn_dt_test[i])-hist_d_test[i]+1]-electric_krx['종가'][list(electric_krx['날짜']).index(byn_dt_test[i])]))\n",
    "    elif btp_cfc_cd_test[i] == 10:\n",
    "        krx_idx_test.append((manufacturing_kosdaq['종가'][list(manufacturing_kosdaq['날짜']).index(byn_dt_test[i])-hist_d_test[i]+1]-manufacturing_kosdaq['종가'][list(manufacturing_kosdaq['날짜']).index(byn_dt_test[i])]))\n",
    "    elif btp_cfc_cd_test[i] == 11:\n",
    "        krx_idx_test.append((steel_krx['종가'][list(steel_krx['날짜']).index(byn_dt_test[i])-hist_d_test[i]+1]-steel_krx['종가'][list(steel_krx['날짜']).index(byn_dt_test[i])]))\n",
    "    elif btp_cfc_cd_test[i] == 12:\n",
    "        krx_idx_test.append((chemical_krx['종가'][list(chemical_krx['날짜']).index(byn_dt_test[i])-hist_d_test[i]+1]-chemical_krx['종가'][list(chemical_krx['날짜']).index(byn_dt_test[i])]))\n",
    "    elif btp_cfc_cd_test[i] == 13:\n",
    "        krx_idx_test.append((IT_kospi['종가'][list(IT_kospi['날짜']).index(byn_dt_test[i])-hist_d_test[i]+1]-IT_kospi['종가'][list(IT_kospi['날짜']).index(byn_dt_test[i])]))        \n",
    "    else:\n",
    "        krx_idx_test.append((etc_krx['종가'][list(etc_krx['날짜']).index(byn_dt_test[i])-hist_d_test[i]+1]-etc_krx['종가'][list(etc_krx['날짜']).index(byn_dt_test[i])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rate: 100%|██████████████████████████████████████████████████████████████████| 70596/70596 [00:00<00:00, 113788.40it/s]\n",
      "rate: 100%|█████████████████████████████████████████████████████████████████| 681472/681472 [00:10<00:00, 65405.41it/s]\n"
     ]
    }
   ],
   "source": [
    "## krx 데이터\n",
    "\n",
    "train_data['krx_idx'] = krx_idx_train\n",
    "test_data['krx_idx'] = krx_idx_test\n",
    "\n",
    "krx_per_day = (etc_krx['종가'][0] - etc_krx['종가'][1226])/len(etc_krx)\n",
    "\n",
    "test_krx_idx = copy.deepcopy(test_data['krx_idx'])\n",
    "train_krx_idx = copy.deepcopy(train_data['krx_idx'])\n",
    "\n",
    "test_krx_idx = (test_data['krx_idx'].max() + test_data['krx_idx'].min())/2 - test_krx_idx \n",
    "train_krx_idx = (train_data['krx_idx'].max() + train_data['krx_idx'].min())/2 - train_krx_idx \n",
    "\n",
    "test_krx_idx = test_krx_idx / krx_per_day\n",
    "train_krx_idx = train_krx_idx / krx_per_day\n",
    "\n",
    "for i in tqdm(range(len(test_krx_idx)), desc = 'rate', mininterval = 0.01):\n",
    "    if test_krx_idx[i] < 0:\n",
    "        test_krx_idx[i] = 0\n",
    "        \n",
    "for i in tqdm(range(len(train_krx_idx)), desc = 'rate', mininterval = 0.01):\n",
    "    if train_krx_idx[i] < 0:\n",
    "        train_krx_idx[i] = 0\n",
    "        \n",
    "test_krx_idx = test_krx_idx * (146/test_krx_idx.max())\n",
    "train_krx_idx = train_krx_idx * (146/train_krx_idx.max())\n",
    "\n",
    "test_krx_idx = np.trunc(test_krx_idx)\n",
    "train_krx_idx = np.trunc(train_krx_idx)\n",
    "\n",
    "train_data['krx_idx'] = train_krx_idx \n",
    "test_data['krx_idx'] = test_krx_idx "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist[\"stk_p\"] = hist[\"tot_aet_amt\"] / hist[\"bnc_qty\"]\n",
    "hist = hist.fillna(0)\n",
    "\n",
    "train_data = pd.merge(train_data, hist, how = \"left\", on = [\"act_id\", \"iem_cd\"])\n",
    "train_data = train_data[(train_data[\"byn_dt\"] == train_data[\"bse_dt\"])]\n",
    "train_data = pd.merge(train_data, kos_data, how = \"left\", on=['byn_dt'])\n",
    "train_data.reset_index(drop = True, inplace = True)\n",
    "\n",
    "test_data = pd.merge(test_data, hist, how = \"left\", on = [\"act_id\", \"iem_cd\"])\n",
    "test_data = test_data[(test_data[\"byn_dt\"] == test_data[\"bse_dt\"])]\n",
    "test_data = pd.merge(test_data, kos_data, how = \"left\", on=['byn_dt'])\n",
    "test_data.reset_index(drop = True, inplace = True)\n",
    "\n",
    "train_data = train_data.drop([\"act_id\", \"iem_cd\", \"byn_dt\", \"bse_dt\"], axis = 1)\n",
    "test_data = test_data.drop([\"act_id\", \"iem_cd\", \"byn_dt\", \"submit_id\", \"hold_d\", \"bse_dt\"], axis = 1)\n",
    "\n",
    "L_encoder = LabelEncoder()\n",
    "L_encoder.fit(iem[\"iem_krl_nm\"])\n",
    "train_data[\"iem_krl_nm\"] = L_encoder.transform(train_data[\"iem_krl_nm\"])\n",
    "test_data[\"iem_krl_nm\"] = L_encoder.transform(test_data[\"iem_krl_nm\"])\n",
    "\n",
    "train_data = train_data.drop(['kospi', 'kospi_idx', 'kosdaq', 'kosdaq_idx', 'other', 'other_idx'], axis =1)\n",
    "test_data = test_data.drop(['kospi', 'kospi_idx', 'kosdaq', 'kosdaq_idx', 'other', 'other_idx'], axis =1)\n",
    "\n",
    "train_data.drop([\"bnc_qty\",\"tot_aet_amt\",\"stk_par_pr\",\"stk_p\"], axis = 1, inplace = True)\n",
    "test_data.drop([\"bnc_qty\",\"tot_aet_amt\",\"stk_par_pr\",\"stk_p\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- test_data의 category를 가지는 feature에 대해 feature 별로 category에 따른 hist_d의 평균값을 list를 생성해 저장한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsg_sgm_cd_test = []\n",
    "for i in range(2,10):\n",
    "    lsg_sgm_cd_test.append(np.trunc(test_data.loc[test_data.loc[:,'lsg_sgm_cd'] == i,'hist_d'].mean()))\n",
    "\n",
    "tot_ivs_te_sgm_cd_test = []\n",
    "for i in range(1,7):\n",
    "    tot_ivs_te_sgm_cd_test.append(np.trunc(test_data.loc[test_data.loc[:,'tot_ivs_te_sgm_cd'] == i,'hist_d'].mean()))\n",
    "    \n",
    "n = [1,2,3,4,5,9,99]\n",
    "tco_cus_grd_cd_test = []\n",
    "for i in (n):\n",
    "    tco_cus_grd_cd_test.append(np.trunc(test_data.loc[test_data.loc[:,'tco_cus_grd_cd'] == i,'hist_d'].mean()))      \n",
    "\n",
    "mrz_btp_dit_cd_test = []\n",
    "for i in range(1,17):\n",
    "    mrz_btp_dit_cd_test.append(np.trunc(test_data.loc[test_data.loc[:,'mrz_btp_dit_cd'] == i,'hist_d'].mean()))      \n",
    "    \n",
    "n = [1,2,3,5,6,8,9,10,11,12,15,99]\n",
    "mrz_pdt_tp_sgm_cd_test = []\n",
    "for i in (n):\n",
    "    mrz_pdt_tp_sgm_cd_test.append(test_data.loc[test_data.loc[:,'mrz_pdt_tp_sgm_cd'] == i,'hist_d'].mean()) \n",
    "    \n",
    "    \n",
    "n = [1,2,3,4,5,9,0,99]\n",
    "ivs_icn_cd_test = []\n",
    "for i in (n):\n",
    "    ivs_icn_cd_test.append(np.trunc(test_data.loc[test_data.loc[:,'ivs_icn_cd'] == i,'hist_d'].mean()))\n",
    "\n",
    "\n",
    "cus_age_stn_cd_test = []\n",
    "for i in range(1,10):\n",
    "    cus_age_stn_cd_test.append(np.trunc(test_data.loc[test_data.loc[:,'cus_age_stn_cd'] == i,'hist_d'].mean()))\n",
    "    \n",
    "btp_cfc_cd_test = []\n",
    "for i in range(1,15):\n",
    "    btp_cfc_cd_test.append(np.trunc(test_data.loc[test_data.loc[:,'btp_cfc_cd'] == i,'hist_d'].mean()))\n",
    "    \n",
    "n = [1,2,3,99]\n",
    "mkt_pr_tal_scl_tp_cd_test = []\n",
    "for i in (n):\n",
    "    mkt_pr_tal_scl_tp_cd_test.append(np.trunc(test_data.loc[test_data.loc[:,'mkt_pr_tal_scl_tp_cd'] == i,'hist_d'].mean()))\n",
    "    \n",
    "n = [1,2,99]\n",
    "stk_dit_cd_test = []\n",
    "for i in (n):\n",
    "    stk_dit_cd_test.append(np.trunc(test_data.loc[test_data.loc[:,'stk_dit_cd'] == i,'hist_d'].mean()))\n",
    "    \n",
    "    \n",
    "\n",
    "n = [1,2,3,4,5,6]\n",
    "cus_aet_stn_cd_test = []\n",
    "for i in (n):\n",
    "    cus_aet_stn_cd_test.append(np.trunc(test_data.loc[test_data.loc[:,'cus_aet_stn_cd'] == i,'hist_d'].mean()))\n",
    "    \n",
    "n = [1,2]\n",
    "sex_dit_cd_test = []\n",
    "for i in (n):\n",
    "    sex_dit_cd_test.append(np.trunc(test_data.loc[test_data.loc[:,'sex_dit_cd'] == i,'hist_d'].mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- train_data의 feature 별로 category에 따른 hold_d의 평균값을 list를 생성해 저장한다.\n",
    "    - train_data의 경우 hist_d의 값이 명확치 않아 hold_d를 사용하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsg_sgm_cd_train = []\n",
    "for i in range(2,10):\n",
    "    lsg_sgm_cd_train.append(np.trunc(train_data.loc[train_data.loc[:,'lsg_sgm_cd'] == i,'hold_d'].mean()))\n",
    "    \n",
    "tot_ivs_te_sgm_cd_train = []\n",
    "for i in range(1,7):\n",
    "    tot_ivs_te_sgm_cd_train.append(np.trunc(train_data.loc[train_data.loc[:,'tot_ivs_te_sgm_cd'] == i,'hold_d'].mean()))    \n",
    "    \n",
    "n = [1,2,3,4,5,9,99]\n",
    "tco_cus_grd_cd_train = []\n",
    "for i in (n):\n",
    "    tco_cus_grd_cd_train.append(np.trunc(train_data.loc[train_data.loc[:,'tco_cus_grd_cd'] == i,'hold_d'].mean()))      \n",
    "    \n",
    "mrz_btp_dit_cd_train = []\n",
    "for i in range(1,17):\n",
    "    mrz_btp_dit_cd_train.append(np.trunc(train_data.loc[train_data.loc[:,'mrz_btp_dit_cd'] == i,'hold_d'].mean()))      \n",
    "    \n",
    "n = [1,2,3,5,6,8,9,10,11,12,15,99]\n",
    "mrz_pdt_tp_sgm_cd_train = []\n",
    "for i in (n):\n",
    "    mrz_pdt_tp_sgm_cd_train.append(np.trunc(train_data.loc[train_data.loc[:,'mrz_pdt_tp_sgm_cd'] == i,'hold_d'].mean())) \n",
    "    \n",
    "n = [1,2,3,4,5,9,0,99]\n",
    "ivs_icn_cd_train = []\n",
    "for i in (n):\n",
    "    ivs_icn_cd_train.append(np.trunc(train_data.loc[train_data.loc[:,'ivs_icn_cd'] == i,'hold_d'].mean()))\n",
    "\n",
    "cus_age_stn_cd_train = []\n",
    "for i in range(1,10):\n",
    "    cus_age_stn_cd_train.append(np.trunc(train_data.loc[train_data.loc[:,'cus_age_stn_cd'] == i,'hold_d'].mean()))\n",
    "    \n",
    "btp_cfc_cd_train = []\n",
    "for i in range(1,15):\n",
    "    btp_cfc_cd_train.append(train_data.loc[train_data.loc[:,'btp_cfc_cd'] == i,'hold_d'].mean())\n",
    "    \n",
    "n = [1,2,3,99]\n",
    "mkt_pr_tal_scl_tp_cd_train = []\n",
    "for i in (n):\n",
    "    mkt_pr_tal_scl_tp_cd_train.append(train_data.loc[train_data.loc[:,'mkt_pr_tal_scl_tp_cd'] == i,'hold_d'].mean())\n",
    "    \n",
    "n = [1,2,99]\n",
    "stk_dit_cd_train = []\n",
    "for i in (n):\n",
    "    stk_dit_cd_train.append(np.trunc(train_data.loc[train_data.loc[:,'stk_dit_cd'] == i,'hold_d'].mean()))    \n",
    "    \n",
    "n = [1,2,3,4,5,6]\n",
    "cus_aet_stn_cd_train = []\n",
    "for i in (n):\n",
    "    cus_aet_stn_cd_train.append(np.trunc(train_data.loc[train_data.loc[:,'cus_aet_stn_cd'] == i,'hold_d'].mean()))\n",
    "    \n",
    "n = [1,2]\n",
    "sex_dit_cd_train = []\n",
    "for i in (n):\n",
    "    sex_dit_cd_train.append(np.trunc(train_data.loc[train_data.loc[:,'sex_dit_cd'] == i,'hold_d'].mean()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- iem_krl_nm feature에 대해서도 위의 과정을 진행해준다.\n",
    "    - iem_krl_nm의 경우 category의 종류가 3000개 가량 존재하는 특징이 있다.\n",
    "- test_data와 train_data에 'sum'이라는 feature을 생성해준다.\n",
    "- 위에서 생성한 feature의 category에 따른 평균값을 저장한 list를 데이터의 featrue의 category에 따라 'sum' feature에 더해준다.\n",
    "- test_data와 train_data에 'diff'라는 feature을 생성해준다.\n",
    "- iem_krl_nm feature의 category에 따른 평균값을 저장한 list를 데이터의 featrue의 category에 따라 'diff' feature에 더해준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "iem_krl_nm_test = []\n",
    "\n",
    "for i in range(0,3075):\n",
    "    iem_krl_nm_test.append(np.trunc(test_data.loc[test_data.loc[:,'iem_krl_nm'] == i,'hist_d'].mean()))\n",
    "\n",
    "iem_krl_nm_train = []\n",
    "\n",
    "for i in range(0,3075):\n",
    "    iem_krl_nm_train.append(np.trunc(train.loc[train_data.loc[:,'iem_krl_nm'] == i,'hold_d'].mean()))\n",
    "\n",
    "\n",
    "test_data.loc[:,'sum'] = 0\n",
    "train_data.loc[:,'sum'] = 0\n",
    "n = [2,3,4,5,6,7,8,9]\n",
    "for i,v in enumerate(n):\n",
    "    test_data.loc[test_data.loc[:,'lsg_sgm_cd'] == v,\"sum\"] = test_data.loc[test_data.loc[:,'lsg_sgm_cd'] == v,\"sum\"]+ lsg_sgm_cd_test[i]\n",
    "\n",
    "n = [1,2,3,4,5,6]\n",
    "for i,v in enumerate(n):\n",
    "    test_data.loc[test_data.loc[:,'tot_ivs_te_sgm_cd'] == v,\"sum\"] = test_data.loc[test_data.loc[:,'tot_ivs_te_sgm_cd'] == v,\"sum\"]+ tot_ivs_te_sgm_cd_test[i]\n",
    "\n",
    "n = [1,2,3,4,5,9,99]\n",
    "for i,v in enumerate(n):\n",
    "    test_data.loc[test_data.loc[:,'tco_cus_grd_cd'] == v,\"sum\"] = test_data.loc[test_data.loc[:,'tco_cus_grd_cd'] == v,\"sum\"]+ tco_cus_grd_cd_test[i]\n",
    "\n",
    "n = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16]\n",
    "for i,v in enumerate(n):\n",
    "    test_data.loc[test_data.loc[:,'mrz_btp_dit_cd'] == v,\"sum\"] = test_data.loc[test_data.loc[:,'mrz_btp_dit_cd'] == v,\"sum\"]+ mrz_btp_dit_cd_test[i]\n",
    "\n",
    "n = [1,2,3,5,6,8,9,10,11,12,15,99]\n",
    "for i,v in enumerate(n):\n",
    "    test_data.loc[test_data.loc[:,'mrz_pdt_tp_sgm_cd'] == v,\"sum\"] = test_data.loc[test_data.loc[:,'mrz_pdt_tp_sgm_cd'] == v,\"sum\"]+ mrz_pdt_tp_sgm_cd_test[i]\n",
    "\n",
    "n = [1,2,3,4,5,9,0,99]\n",
    "for i,v in enumerate(n):\n",
    "    test_data.loc[test_data.loc[:,'ivs_icn_cd'] == v,\"sum\"] = test_data.loc[test_data.loc[:,'ivs_icn_cd'] == v,\"sum\"]+ ivs_icn_cd_test[i]\n",
    "\n",
    "n = [1,2,3,4,5,6,7,8,9]\n",
    "for i,v in enumerate(n):\n",
    "    test_data.loc[test_data.loc[:,'cus_age_stn_cd'] == v,\"sum\"] = test_data.loc[test_data.loc[:,'cus_age_stn_cd'] == v,\"sum\"]+ cus_age_stn_cd_test[i]\n",
    "\n",
    "n = [1,2,3,4,5,6,7,8,9,10,11,12,13,14]\n",
    "for i,v in enumerate(n):\n",
    "    test_data.loc[test_data.loc[:,'btp_cfc_cd'] == v,\"sum\"] = test_data.loc[test_data.loc[:,'btp_cfc_cd'] == v,\"sum\"]+ btp_cfc_cd_test[i]\n",
    "\n",
    "n = [1,2,3,99]\n",
    "for i,v in enumerate(n):\n",
    "    test_data.loc[test_data.loc[:,'mkt_pr_tal_scl_tp_cd'] == v,\"sum\"] = test_data.loc[test_data.loc[:,'mkt_pr_tal_scl_tp_cd'] == v,\"sum\"]+ mkt_pr_tal_scl_tp_cd_test[i]\n",
    "\n",
    "n = [1,2,99]\n",
    "for i,v in enumerate(n):\n",
    "    test_data.loc[test_data.loc[:,'stk_dit_cd'] == v,\"sum\"] = test_data.loc[test_data.loc[:,'stk_dit_cd'] == v,\"sum\"]+ stk_dit_cd_test[i]\n",
    "\n",
    "n = [1,2,3,4,5,6]\n",
    "for i,v in enumerate(n):\n",
    "    test_data.loc[test_data.loc[:,'cus_aet_stn_cd'] == v,\"sum\"] = test_data.loc[test_data.loc[:,'cus_aet_stn_cd'] == v,\"sum\"]+ cus_aet_stn_cd_test[i]\n",
    "n = [1,2]\n",
    "for i,v in enumerate(n):\n",
    "    test_data.loc[test_data.loc[:,'sex_dit_cd'] == v,\"sum\"] = test_data.loc[test_data.loc[:,'sex_dit_cd'] == v,\"sum\"]+ sex_dit_cd_test[i]\n",
    "n = [2,3,4,5,6,7,8,9]\n",
    "for i,v in enumerate(n):\n",
    "    train_data.loc[train_data.loc[:,'lsg_sgm_cd'] == v,\"sum\"] = train_data.loc[train_data.loc[:,'lsg_sgm_cd'] == v,\"sum\"]+ lsg_sgm_cd_train[i]\n",
    "\n",
    "n = [1,2,3,4,5,6]\n",
    "for i,v in enumerate(n):\n",
    "    train_data.loc[train_data.loc[:,'tot_ivs_te_sgm_cd'] == v,\"sum\"] = train_data.loc[train_data.loc[:,'tot_ivs_te_sgm_cd'] == v,\"sum\"]+ tot_ivs_te_sgm_cd_train[i]\n",
    "\n",
    "n = [1,2,3,4,5,9,99]\n",
    "for i,v in enumerate(n):\n",
    "    train_data.loc[train_data.loc[:,'tco_cus_grd_cd'] == v,\"sum\"] = train_data.loc[train_data.loc[:,'tco_cus_grd_cd'] == v,\"sum\"]+ tco_cus_grd_cd_train[i]\n",
    "\n",
    "n = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16]\n",
    "for i,v in enumerate(n):\n",
    "    train_data.loc[train_data.loc[:,'mrz_btp_dit_cd'] == v,\"sum\"] = train_data.loc[train_data.loc[:,'mrz_btp_dit_cd'] == v,\"sum\"]+ mrz_btp_dit_cd_train[i]\n",
    "\n",
    "n = [1,2,3,5,6,8,9,10,11,12,15,99]\n",
    "for i,v in enumerate(n):\n",
    "    train_data.loc[train_data.loc[:,'mrz_pdt_tp_sgm_cd'] == v,\"sum\"] = train_data.loc[train_data.loc[:,'mrz_pdt_tp_sgm_cd'] == v,\"sum\"]+ mrz_pdt_tp_sgm_cd_train[i]\n",
    "\n",
    "n = [1,2,3,4,5,9,0,99]\n",
    "for i,v in enumerate(n):\n",
    "    train_data.loc[train_data.loc[:,'ivs_icn_cd'] == v,\"sum\"] = train_data.loc[train_data.loc[:,'ivs_icn_cd'] == v,\"sum\"]+ ivs_icn_cd_train[i]\n",
    "\n",
    "n = [1,2,3,4,5,6,7,8,9]\n",
    "for i,v in enumerate(n):\n",
    "    train_data.loc[train_data.loc[:,'cus_age_stn_cd'] == v,\"sum\"] = train_data.loc[train_data.loc[:,'cus_age_stn_cd'] == v,\"sum\"]+ cus_age_stn_cd_train[i]\n",
    "\n",
    "n = [1,2,3,4,5,6,7,8,9,10,11,12,13,14]\n",
    "for i,v in enumerate(n):\n",
    "    train_data.loc[train_data.loc[:,'btp_cfc_cd'] == v,\"sum\"] = train_data.loc[train_data.loc[:,'btp_cfc_cd'] == v,\"sum\"]+ btp_cfc_cd_train[i]\n",
    "\n",
    "n = [1,2,3,99]\n",
    "for i,v in enumerate(n):\n",
    "    train_data.loc[train_data.loc[:,'mkt_pr_tal_scl_tp_cd'] == v,\"sum\"] = train_data.loc[train_data.loc[:,'mkt_pr_tal_scl_tp_cd'] == v,\"sum\"]+ mkt_pr_tal_scl_tp_cd_train[i]\n",
    "\n",
    "n = [1,2,99]\n",
    "for i,v in enumerate(n):\n",
    "    train_data.loc[train_data.loc[:,'stk_dit_cd'] == v,\"sum\"] = train_data.loc[train_data.loc[:,'stk_dit_cd'] == v,\"sum\"]+ stk_dit_cd_train[i]\n",
    "\n",
    "n = [1,2,3,4,5,6]\n",
    "for i,v in enumerate(n):\n",
    "    train_data.loc[train_data.loc[:,'cus_aet_stn_cd'] == v,\"sum\"] = train_data.loc[train_data.loc[:,'cus_aet_stn_cd'] == v,\"sum\"]+ cus_aet_stn_cd_train[i]\n",
    "n = [1,2]\n",
    "for i,v in enumerate(n):\n",
    "    train_data.loc[train_data.loc[:,'sex_dit_cd'] == v,\"sum\"] = train_data.loc[train_data.loc[:,'sex_dit_cd'] == v,\"sum\"]+ sex_dit_cd_train[i]\n",
    "for i in range(0,3075):\n",
    "    if np.isnan(iem_krl_nm_test[i]):\n",
    "        continue\n",
    "    test_data.loc[test_data.loc[:,'iem_krl_nm'] == i,'sum']= test_data.loc[test_data.loc[:,'iem_krl_nm'] == i,'sum']+ np.trunc(iem_krl_nm_test[i])\n",
    "    \n",
    "for i in range(0,3075):\n",
    "    if np.isnan(iem_krl_nm_train[i]):\n",
    "        continue\n",
    "    train_data.loc[train_data.loc[:,'iem_krl_nm'] == i,'sum']=train_data.loc[train_data.loc[:,'iem_krl_nm'] == i,'sum']+ np.trunc(iem_krl_nm_train[i])\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "for i in range(0,3075):\n",
    "    if np.isnan(iem_krl_nm_test[i]):\n",
    "        continue\n",
    "    test_data.loc[test_data.loc[:,'iem_krl_nm'] == i,'diff']= np.trunc(iem_krl_nm_test[i])\n",
    "    \n",
    "for i in range(0,3075):\n",
    "    if np.isnan(iem_krl_nm_train[i]):\n",
    "        continue\n",
    "    train_data.loc[train_data.loc[:,'iem_krl_nm'] == i,'diff']=np.trunc(iem_krl_nm_train[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. train_data에 대해서 hold_d의 값을 30 ~ 60, 60 ~ 100, 100 ~ 147,그리고 147초과하는 범위로 구간을 나눈다.\n",
    "2. 나눈 구간 별로 앞서 생성한 sum feature의 max값은 550, 465, 410, 879이다\n",
    "3. 147미만의 3구역에서는 sum feature의 max값을 hold_d * sum에 나눠준다.\n",
    "    - (hold_d * sum)/(sum feature의 max)가 0보다는 크며 hold_d보다 작은 값을 가진다.\n",
    "    - 3번의 계산 결과를 hold_d - hist_d라고 가정한다.\n",
    "4. 3번의 계산 결과인 (hold_d - hist_d)를 hold_d에 빼준 결과를 hist_d에 넣어준다.\n",
    "    - sum feature값이 클 수록 hold_d - hist_d가 클거라는 가정을 통해서 나온 결과이다.\n",
    "5. 147이상의 구역에서는 max값인 879보다 작은 720을 나누어 주었다.\n",
    "    - 879값을 그대로 사용하기에는 min값과 max값의 차이가 다른 구간에 비해 커져서 적정선의 값인 720으로 나누어주었다.\n",
    "6. 다음은 (hold_d - hist_d) >146인 경우에는 hold_d - 146으로 일괄 처리한다.\n",
    "7. train_label를 생성한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(30,60):\n",
    "    train_data.loc[train_data[train_data.loc[:,'hold_d']== i].index,'hist_d'] = train_data.loc[train_data[train_data.loc[:,'hold_d']== i].index,'hold_d'] -np.trunc(train_data.loc[train_data[train_data.loc[:,'hold_d']== i].index,'sum']*i/550)\n",
    "for i in range(60,100):\n",
    "    train_data.loc[train_data[train_data.loc[:,'hold_d']== i].index,'hist_d'] = train_data.loc[train_data[train_data.loc[:,'hold_d']== i].index,'hold_d'] -np.trunc(train_data.loc[train_data[train_data.loc[:,'hold_d']== i].index,'sum']*i/465)\n",
    "for i in range(100,147):\n",
    "    train_data.loc[train_data[train_data.loc[:,'hold_d']== i].index,'hist_d'] = train_data.loc[train_data[train_data.loc[:,'hold_d']== i].index,'hold_d'] -np.trunc(train_data.loc[train_data[train_data.loc[:,'hold_d']== i].index,'sum']*i/410)\n",
    "\n",
    "train_data.loc[train_data[train_data.loc[:,'hold_d']> 146].index,'hist_d'] = train_data.loc[train_data[train_data.loc[:,'hold_d']> 146].index,'hold_d'] -np.trunc(train_data.loc[train_data[train_data.loc[:,'hold_d']> 146].index,'sum']*146/720) \n",
    "train_data.loc[train_data.loc[train_data[train_data.loc[:,'hold_d']> 146].index,'hist_d'][(train_data.loc[train_data[train_data.loc[:,'hold_d']> 146].index,'sum']*146/720)>146].index,'hist_d'] =train_data.loc[train_data.loc[train_data[train_data.loc[:,'hold_d']> 146].index,'hist_d'][(train_data.loc[train_data[train_data.loc[:,'hold_d']> 146].index,'sum']*146/720)>146].index,'hold_d']- 146\n",
    "train_data.loc[train_data.loc[train_data.loc[:,'hold_d']-train_data.loc[:,'hist_d']>146].index,'hist_d'] =train_data.loc[train_data.loc[train_data.loc[:,'hold_d']-train_data.loc[:,'hist_d']>146].index,'hold_d']-146\n",
    "train_data.hist_d = np.trunc(train_data.hist_d)\n",
    "train_data.hist_d = train_data.hist_d.fillna(0)\n",
    "train_label = train_data[\"hold_d\"]\n",
    "train_data.drop([\"hold_d\"], axis = 1, inplace = True)\n",
    "\n",
    "\n",
    "test_data = np.trunc(test_data)\n",
    "train_data = np.trunc(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 마지막으로 기존 kos_idx, krx_idx은 hold_d - hist_d 값을 나타내는 지표이므로 이에 hist_d 값을 더해줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['kos_idx'] = train_data['kos_idx'] + train_data['hist_d']\n",
    "test_data['kos_idx'] = test_data['kos_idx'] + test_data['hist_d']\n",
    "\n",
    "train_data['krx_idx'] = train_data['krx_idx'] + train_data['hist_d']\n",
    "test_data['krx_idx'] = test_data['krx_idx'] + test_data['hist_d']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 150 rounds\n",
      "[500]\tvalid_0's rmse: 4.97531\tvalid_0's l2: 24.7538\n",
      "[1000]\tvalid_0's rmse: 4.8384\tvalid_0's l2: 23.4101\n",
      "[1500]\tvalid_0's rmse: 4.8268\tvalid_0's l2: 23.298\n",
      "Early stopping, best iteration is:\n",
      "[1372]\tvalid_0's rmse: 4.82651\tvalid_0's l2: 23.2952\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[500]\tvalid_0's rmse: 2.29091\tvalid_0's l2: 5.24828\n",
      "[1000]\tvalid_0's rmse: 2.19433\tvalid_0's l2: 4.81508\n",
      "[1500]\tvalid_0's rmse: 2.19031\tvalid_0's l2: 4.79745\n",
      "[2000]\tvalid_0's rmse: 2.18877\tvalid_0's l2: 4.79071\n",
      "Early stopping, best iteration is:\n",
      "[1875]\tvalid_0's rmse: 2.18825\tvalid_0's l2: 4.78845\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[500]\tvalid_0's rmse: 2.19804\tvalid_0's l2: 4.83138\n",
      "[1000]\tvalid_0's rmse: 2.10926\tvalid_0's l2: 4.44899\n",
      "Early stopping, best iteration is:\n",
      "[1106]\tvalid_0's rmse: 2.10273\tvalid_0's l2: 4.42148\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[500]\tvalid_0's rmse: 1.91235\tvalid_0's l2: 3.65706\n",
      "[1000]\tvalid_0's rmse: 1.78728\tvalid_0's l2: 3.19435\n",
      "Early stopping, best iteration is:\n",
      "[926]\tvalid_0's rmse: 1.78688\tvalid_0's l2: 3.19293\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[500]\tvalid_0's rmse: 2.05766\tvalid_0's l2: 4.23396\n",
      "[1000]\tvalid_0's rmse: 2.00175\tvalid_0's l2: 4.00702\n",
      "[1500]\tvalid_0's rmse: 1.99777\tvalid_0's l2: 3.99108\n",
      "Early stopping, best iteration is:\n",
      "[1753]\tvalid_0's rmse: 1.99583\tvalid_0's l2: 3.98332\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[500]\tvalid_0's rmse: 1.8659\tvalid_0's l2: 3.48158\n",
      "[1000]\tvalid_0's rmse: 1.80546\tvalid_0's l2: 3.25969\n",
      "Early stopping, best iteration is:\n",
      "[1233]\tvalid_0's rmse: 1.80233\tvalid_0's l2: 3.24838\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[500]\tvalid_0's rmse: 1.63582\tvalid_0's l2: 2.67592\n",
      "[1000]\tvalid_0's rmse: 1.58817\tvalid_0's l2: 2.52228\n",
      "[1500]\tvalid_0's rmse: 1.58072\tvalid_0's l2: 2.49869\n",
      "[2000]\tvalid_0's rmse: 1.57758\tvalid_0's l2: 2.48877\n",
      "Early stopping, best iteration is:\n",
      "[2234]\tvalid_0's rmse: 1.57656\tvalid_0's l2: 2.48554\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[500]\tvalid_0's rmse: 1.68712\tvalid_0's l2: 2.84639\n",
      "[1000]\tvalid_0's rmse: 1.6578\tvalid_0's l2: 2.74829\n",
      "Early stopping, best iteration is:\n",
      "[1150]\tvalid_0's rmse: 1.65684\tvalid_0's l2: 2.74513\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[500]\tvalid_0's rmse: 1.51428\tvalid_0's l2: 2.29303\n",
      "[1000]\tvalid_0's rmse: 1.47687\tvalid_0's l2: 2.18114\n",
      "[1500]\tvalid_0's rmse: 1.46804\tvalid_0's l2: 2.15514\n",
      "[2000]\tvalid_0's rmse: 1.46643\tvalid_0's l2: 2.15041\n",
      "[2500]\tvalid_0's rmse: 1.4645\tvalid_0's l2: 2.14477\n",
      "[3000]\tvalid_0's rmse: 1.46168\tvalid_0's l2: 2.1365\n",
      "Early stopping, best iteration is:\n",
      "[3142]\tvalid_0's rmse: 1.46134\tvalid_0's l2: 2.13552\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[500]\tvalid_0's rmse: 1.45386\tvalid_0's l2: 2.1137\n",
      "[1000]\tvalid_0's rmse: 1.44233\tvalid_0's l2: 2.08032\n",
      "Early stopping, best iteration is:\n",
      "[856]\tvalid_0's rmse: 1.44065\tvalid_0's l2: 2.07548\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "\n",
    "folds = KFold(n_splits=10)\n",
    "for train_idx, val_idx in folds.split(train_data):\n",
    "    \n",
    "    train_x = train_data.loc[train_idx, :]\n",
    "    train_y = train_label[train_idx]\n",
    "    val_x = train_data.loc[val_idx, :]\n",
    "    val_y = train_label[val_idx]\n",
    "    \n",
    "    model = LGBMRegressor(objective= \"regression\",\n",
    "                          max_depth= 5,\n",
    "                          n_estimators= 3500,\n",
    "                          learning_rate= 0.01,\n",
    "                          num_leaves = 31)\n",
    "\n",
    "    model.fit(train_x, train_y,\n",
    "              eval_set=[(val_x, val_y)],\n",
    "              eval_metric=[\"rmse\"],\n",
    "              early_stopping_rounds=150,\n",
    "              verbose=500)\n",
    "    \n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "최종 결과 data 파일에 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "for i in models:\n",
    "    result.append(i.predict(test_data))\n",
    "predict = np.mean(result, axis = 0)\n",
    "submission[\"hold_d\"] = np.round(predict)\n",
    "submission.loc[submission[\"hold_d\"]-test.hist_d >146,'hold_d'] = test.loc[submission[\"hold_d\"]-test.hist_d >146,'hist_d']+138\n",
    "submission.loc[(submission[\"hold_d\"]-test.hist_d) <1,'hold_d'] = test.loc[submission[\"hold_d\"]-test.hist_d<1,'hist_d']+9\n",
    "submission.to_csv(\"data/dacon_1011_R2.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
